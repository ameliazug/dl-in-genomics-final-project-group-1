# -*- coding: utf-8 -*-
"""ConvertBAM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LMKz4v21JOji08zvdXKfWYiQdKWntFG9
"""

#INSTALL RELEVANT TOOLS:

!apt-get update
!apt-get install -y samtools bedtools
!pip install deeptools

from google.colab import drive
import pandas as pd
import numpy as np
import os
import subprocess

drive.mount('/content/drive/')

import os
import subprocess
import sys


INPUT_BAM = "Data/ENCODE/BAM/H1/ENCFF139MSY.bam"

# Define output file names and paths
# Ensure the output directories exist or the script has permission to create them
SORTED_BAM = "Data/ENCODE/BAM/H1/input_control.sorted.bam"
OUTPUT_BIGWIG = "Data/ENCODE/BAM/H1/input_control.bigwig"




# --- deepTools Configuration ---
# If your library is single-end, you need to specify the fragment length for bamCoverage.
# We are setting a common estimated fragment length for ChIP-seq single-end data.
# Ideally, find the precise fragment length in the dataset's metadata on ENCODE.
# For deepTools v3.5.6, use --extendReads followed by the fragment length.
ESTIMATED_FRAGMENT_LENGTH = 180 # Set to 180 as a common estimate for single-end ChIP-seq

# --- Check if Input BAM exists ---
if not os.path.exists(INPUT_BAM):
    print(f"Error: Input BAM file not found at {INPUT_BAM}")
    sys.exit("Exiting: Input file not found.")
else:
    print(f"Input BAM file found: {INPUT_BAM}")
    # Optional: Print file size to estimate resource needs
    try:
        file_size_gb = os.path.getsize(INPUT_BAM) / (1024**3)
        print(f"Input BAM file size: {file_size_gb:.2f} GB")
        # You might add a check here based on your system's resources
    except Exception as e:
        print(f"Could not determine file size: {e}")


    # --- Step 1: Sort the BAM file by coordinate ---
    # This is a crucial step for indexing and many downstream analyses.
    print(f"\nSorting BAM file: {INPUT_BAM} -> {SORTED_BAM}")
    # Use -@ for multiple threads if your system supports it (e.g., -@ 4)
    # Added explicit stderr capture and decoding for better error reporting
    sort_command = f"samtools sort {INPUT_BAM} -o {SORTED_BAM}"
    try:
        result = subprocess.run(sort_command, shell=True, check=True, capture_output=True, text=True)
        print("BAM sorting complete.")
        print(f"Samtools sort stdout:\n{result.stdout}")
        if result.stderr:
             print(f"Samtools sort stderr:\n{result.stderr}")
    except subprocess.CalledProcessError as e:
        print(f"Error during BAM sorting: {e}")
        # Explicitly print stderr from the failed process
        print(f"Samtools sort stderr (from error):")
        print(e.stderr)
        sys.exit("Exiting due to BAM sorting failure.")


    # --- Step 2: Index the sorted BAM file ---
    # Creates a .bai index file which allows for quick access to regions.
    print(f"\nIndexing sorted BAM file: {SORTED_BAM}")
    index_command = f"samtools index {SORTED_BAM}"
    try:
        result = subprocess.run(index_command, shell=True, check=True, capture_output=True, text=True)
        print("BAM indexing complete.")
        print(f"Samtools index stdout:\n{result.stdout}")
        if result.stderr:
             print(f"Samtools index stderr:\n{result.stderr}")
    except subprocess.CalledProcessError as e:
        print(f"Error during BAM indexing: {e}")
        print(f"Stdout: {e.stdout}")
        print(f"Stderr: {e.stderr}")
        print("Warning: BAM indexing failed. BigWig generation might be affected.")


    # --- Step 3: Generate BigWig file using deepTools bamCoverage ---
    # This tool calculates coverage and outputs in BigWig format.
    # --binSize: Size of the bins in base pairs for calculating coverage.
    # --normalizeUsing: Normalization method. 'None' means raw counts per bin.
    #                   Other options include 'BPM', 'RPKM', 'CPM', etc.
    #                   'BPM' is common for visualization, but for M2A's sum of signals,
    #                   raw counts per bin might be a starting point, or you might
    #                   need to calculate sums within your specific windows later.
    # --extendReads: Specify the fragment length for single-end reads in deepTools v3.5.6.
    #                Remove this flag if you are using paired-end data or
    #                do not want to extend reads.
    # Consult deepTools documentation for other options:
    # https://deeptools.readthedocs.io/en/latest/content/tools/bamCoverage.html
    print(f"\nGenerating BigWig file: {SORTED_BAM} -> {OUTPUT_BIGWIG}")

    # Construct the bamCoverage command based on whether fragment length is specified
    coverage_command_parts = [
        "bamCoverage",
        "-b", SORTED_BAM,
        "-o", OUTPUT_BIGWIG,
        "--binSize", "50", # Example bin size, adjust as needed
        "--normalizeUsing", "None" # Using None for raw counts per bin
    ]

    if ESTIMATED_FRAGMENT_LENGTH is not None:
        # For deepTools v3.5.6, use --extendReads followed by the fragment length
        coverage_command_parts.extend(["--extendReads", str(ESTIMATED_FRAGMENT_LENGTH)])
    # else: if using paired-end and want auto-extension, would use --extendReads here without a value

    coverage_command = " ".join(coverage_command_parts)

    try:
        result = subprocess.run(coverage_command, shell=True, check=True, capture_output=True, text=True)
        print("BigWig generation complete.")
        print(f"bamCoverage stdout:\n{result.stdout}")
        if result.stderr:
             print(f"bamCoverage stderr:\n{result.stderr}")
    except subprocess.CalledProcessError as e:
        print(f"Error during BigWig generation: {e}")
        print(f"Stdout: {e.stdout}")
        print(f"Stderr: {e.stderr}")
        sys.exit("Exiting due to BigWig generation failure.")

    print("\nScript finished successfully.")

